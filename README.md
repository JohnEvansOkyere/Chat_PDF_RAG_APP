ğŸ“„ **PDF Question-Answering Assistant** ğŸ¤–

This project enables users to upload a PDF file, extract its content, split it into smaller chunks, and leverage the LLama2 
language model to answer questions based on the content of the PDF. Built using LangChain, Streamlit, and Ollama API, this 
tool provides an efficient solution for document-based question answering.

ğŸ› ï¸ **Requirements**

Python 3.x
Streamlit ğŸ–¥ï¸
LangChain ğŸ”—
dotenv ğŸŒ±
PDFPlumber ğŸ“‘
Ollama API ğŸ”‘

ğŸ“¦ **Installation**

To run this project locally, follow these steps:

Step 1: Install Dependencies

pip install -r requirements.txt

Note: You need to create a requirements.txt file with the following dependencies:

streamlit
langchain
langchain_community
python-dotenv
pdfplumber

Step 2: Set Up Environment Variables

Create a .env file in the project directory and add your Ollama API key:

OLLAMA_API_KEY=your_ollama_api_key

Step 3: Run the Streamlit App

After setting up your environment and dependencies, run the Streamlit app with the following command:

streamlit run app.py

Step 4: Upload PDF and Ask Questions

Open the app in your browser.

Upload a PDF file using the file uploader. ğŸ“¤

Ask a question related to the content in the PDF. â“

The app will return a concise answer based on the content of the uploaded PDF. ğŸ’¬

ğŸ§‘â€ğŸ’» **Code Overview**

app.py

Environment Setup: The .env file loads the Ollama API key for model interaction. ğŸ”‘

PDF Upload: Users can upload PDFs using the st.file_uploader() function. ğŸ“¥

Document Loading: The PDF content is extracted using PDFPlumberLoader for processing. ğŸ“ƒ

Text Splitting: The document is split into smaller, manageable chunks using RecursiveCharacterTextSplitter. ğŸ§©

Indexing: Text chunks are indexed using InMemoryVectorStore for efficient retrieval. ğŸ“š

Model Interaction: The Ollama LLM is used to generate responses to user queries based on document content. ğŸ§ 

Question Answering: The answer_question() function combines relevant document content and provides an answer using a ChatPromptTemplate. ğŸ”

ğŸš€ **Features**

PDF Upload: Upload PDFs to extract and process content with ease. ğŸ“‚

Text Splitting: Breaks documents into manageable chunks to improve retrieval and performance. âœ‚ï¸

Question Answering: Get concise answers based on the PDF's content with LLama2. ğŸ¤–

Vector Store: Use vector stores for fast and efficient document content retrieval. ğŸ“ˆ

âš™ï¸ **Future Improvements**

Multi-Document Support: Handle multiple PDFs and improve content retrieval. ğŸ“„ğŸ“„

Advanced Error Handling: Enhance user experience by adding better error handling. âš ï¸

Customizable Models: Allow users to select between various models for answering questions. âš™ï¸
